\chapter{Conclusion}
The goal of this project was to read, analyse and discuss a recent paper on the subject of super-resolution. The paper in question written in 2015 by Qingqing Huang and Sham Kakade highlights an algorithm that is capable to efficiently recover the location of some fine details of a low resolution image. It describes a single main algorithm that aims at creating a sampling set randomly which we then use to construct the measurements that we store in a tensor. A tensor decomposition procedure then aims at recovering our desired estimates. The overall runs in cubic time complexity due to the SVD computation and uses a quadratic amount of samples due to the procedure of taking the measurements.\par

Although this procedure is in itself a huge improvement compared to previous results, it is supposedly information-theoretically possible to reduce the amount of samples used from quadratic to linear in the number of measurements. Future work could eventually imply taking measurements from a lower dimension and tensoring them in higher dimension or simply generating a constant amount of measurements per point source and storing them in a smaller tensor.\par

The project was an excellent opportunity for me to improve both my research and my personal skills. Indeed, doing a 12 credits project in the theoretical computer science lab at EPFL during a busy semester given that I don't really have the same background as a standard EPFL student is a huge challenge that I very much enjoyed taking part in. In the near future, I would definitely enjoy continuing this work with Prof. Kapralov to eventually find a real improvement that could boost both the sample complexity and the robustness of the main procedure.